{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98d74641",
   "metadata": {},
   "source": [
    "# US EPA Air Quality System API\n",
    "This section of code goes through how I grabbed AQI data from the EPA. A lot of functions used in this code were taken from [this](https://colab.research.google.com/drive/1bxl9qrb_52RocKNGfbZ5znHVqFDMkUzf) notebook, I will go into greater detail on this fact throughout the notebook. The code to make the 'signup request' from the API was ommited for privacy reasons, see linked notebook for information on how to sign up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6685ea90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS SECTION OF CODE WAS TAKEN FROM THE SECOND CELL FROM THE STATED NOTEBOOK\n",
    "\n",
    "import requests\n",
    "\n",
    "API_REQUEST_URL = 'https://aqs.epa.gov/data/api'\n",
    "\n",
    "API_ACTION_SIGNUP = '/signup?email={email}'\n",
    "tions/requests\n",
    "API_ACTION_LIST_CLASSES = '/list/classes?email={email}&key={key}'\n",
    "API_ACTION_LIST_PARAMS = '/list/parametersByClass?email={email}&key={key}&pc={pclass}'\n",
    "API_ACTION_LIST_SITES = '/list/sitesByCounty?email={email}&key={key}&state={state}&county={county}'\n",
    "\n",
    "API_ACTION_MONITORS_COUNTY = '/monitors/byCounty?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&state={state}&county={county}'\n",
    "API_ACTION_MONITORS_BOX = '/monitors/byBox?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&minlat={minlat}&maxlat={maxlat}&minlon={minlon}&maxlon={maxlon}'\n",
    "\n",
    "API_ACTION_DAILY_SUMMARY_COUNTY = '/dailyData/byCounty?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&state={state}&county={county}'\n",
    "API_ACTION_DAILY_SUMMARY_BOX = '/dailyData/byBox?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&minlat={minlat}&maxlat={maxlat}&minlon={minlon}&maxlon={maxlon}'\n",
    "\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (1.0/100.0)-API_LATENCY_ASSUMED\n",
    "#\n",
    "#\n",
    "#    This is a template that covers most of the parameters for the actions we might take, from the set of actions\n",
    "#    above. In the examples below, most of the time parameters can either be supplied as individual values to a\n",
    "#    function - or they can be set in a copy of the template and passed in with the template.\n",
    "# \n",
    "AQS_REQUEST_TEMPLATE = {\n",
    "    \"email\":      \"\",     \n",
    "    \"key\":        \"\",      \n",
    "    \"state\":      \"\",     # the two digit state FIPS # as a string\n",
    "    \"county\":     \"\",     # the three digit county FIPS # as a string\n",
    "    \"begin_date\": \"\",     # the start of a time window in YYYYMMDD format\n",
    "    \"end_date\":   \"\",     # the end of a time window in YYYYMMDD format, begin_date and end_date must be in the same year\n",
    "    \"minlat\":    0.0,\n",
    "    \"maxlat\":    0.0,\n",
    "    \"minlon\":    0.0,\n",
    "    \"maxlon\":    0.0,\n",
    "    \"param\":     \"\",     # a list of comma separated 5 digit codes, max 5 codes requested\n",
    "    \"pclass\":    \"\"      # parameter class is only used by the List calls\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e3fd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "USERNAME = \"fake_name@gmail.com\"\n",
    "APIKEY = 'fake_password'\n",
    "#   Gaseous AQI pollutants CO, SO2, NO2, and O2\n",
    "AQI_PARAMS_GASEOUS = \"42101,42401,42602,44201\"\n",
    "#\n",
    "#   Particulate AQI pollutants PM10, PM2.5, and Acceptable PM2.5\n",
    "AQI_PARAMS_PARTICULATES = \"81102,88101,88502\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc841aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS SECTION OF CODE WAS TAKEN FROM THE 13th CELL FROM THE STATED NOTEBOOK\n",
    "CITY_LOCATIONS = {\n",
    "    'mine' :       {'city'   : 'Loveland',\n",
    "                       'county' : 'Larimer',\n",
    "                       'state'  : 'Colorado',\n",
    "                       'fips'   : '08069',\n",
    "                       'latlon' : [40.3955, -105.0746] }\n",
    "}\n",
    "def request_daily_summary(email_address = None, key = None, param=None,\n",
    "                          begin_date = None, end_date = None, fips = None,\n",
    "                          endpoint_url = API_REQUEST_URL, \n",
    "                          endpoint_action = API_ACTION_DAILY_SUMMARY_COUNTY, \n",
    "                          request_template = AQS_REQUEST_TEMPLATE,\n",
    "                          headers = None):\n",
    "    \n",
    "    #  This prioritizes the info from the call parameters - not what's already in the template\n",
    "    if email_address:\n",
    "        request_template['email'] = email_address\n",
    "    if key:\n",
    "        request_template['key'] = key\n",
    "    if param:\n",
    "        request_template['param'] = param\n",
    "    if begin_date:\n",
    "        request_template['begin_date'] = begin_date\n",
    "    if end_date:\n",
    "        request_template['end_date'] = end_date\n",
    "    if fips and len(fips)==5:\n",
    "        request_template['state'] = fips[:2]\n",
    "        request_template['county'] = fips[2:]            \n",
    "\n",
    "    # Make sure there are values that allow us to make a call - these are always required\n",
    "    if not request_template['email']:\n",
    "        raise Exception(\"Must supply an email address to call 'request_daily_summary()'\")\n",
    "    if not request_template['key']: \n",
    "        raise Exception(\"Must supply a key to call 'request_daily_summary()'\")\n",
    "    if not request_template['param']: \n",
    "        raise Exception(\"Must supply param values to call 'request_daily_summary()'\")\n",
    "    if not request_template['begin_date']: \n",
    "        raise Exception(\"Must supply a begin_date to call 'request_daily_summary()'\")\n",
    "    if not request_template['end_date']: \n",
    "        raise Exception(\"Must supply an end_date to call 'request_daily_summary()'\")\n",
    "    # Note we're not validating FIPS fields because not all of the daily summary actions require the FIPS numbers\n",
    "        \n",
    "    # compose the request\n",
    "    request_url = endpoint_url+endpoint_action.format(**request_template)\n",
    "        \n",
    "    # make the request\n",
    "    try:\n",
    "        # Wait first, to make sure we don't exceed a rate limit in the situation where an exception occurs\n",
    "        # during the request processing - throttling is always a good practice with a free data source\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f557c00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS SECTION OF CODE WAS TAKEN FROM THE 15th CELL FROM THE STATED NOTEBOOK\n",
    "\n",
    "EXTRACTION_FIELDS = ['sample_duration','observation_count','arithmetic_mean','aqi']\n",
    "\n",
    "#\n",
    "#    The function creates a summary record\n",
    "def extract_summary_from_response(r=None, fields=EXTRACTION_FIELDS):\n",
    "    ## the result will be structured around monitoring site, parameter, and then date\n",
    "    result = dict()\n",
    "    data = r[\"Data\"]\n",
    "    for record in data:\n",
    "        # make sure the record is set up\n",
    "        site = record['site_number']\n",
    "        param = record['parameter_code']\n",
    "        #date = record['date_local']    # this version keeps the respnse value YYYY-\n",
    "        date = record['date_local'].replace('-','') # this puts it in YYYYMMDD format\n",
    "        if site not in result:\n",
    "            result[site] = dict()\n",
    "            result[site]['local_site_name'] = record['local_site_name']\n",
    "            result[site]['site_address'] = record['site_address']\n",
    "            result[site]['state'] = record['state']\n",
    "            result[site]['county'] = record['county']\n",
    "            result[site]['city'] = record['city']\n",
    "            result[site]['pollutant_type'] = dict()\n",
    "        if param not in result[site]['pollutant_type']:\n",
    "            result[site]['pollutant_type'][param] = dict()\n",
    "            result[site]['pollutant_type'][param]['parameter_name'] = record['parameter']\n",
    "            result[site]['pollutant_type'][param]['units_of_measure'] = record['units_of_measure']\n",
    "            result[site]['pollutant_type'][param]['method'] = record['method']\n",
    "            result[site]['pollutant_type'][param]['data'] = dict()\n",
    "        if date not in result[site]['pollutant_type'][param]['data']:\n",
    "            result[site]['pollutant_type'][param]['data'][date] = list()\n",
    "        \n",
    "        # now extract the specified fields\n",
    "        extract = dict()\n",
    "        for k in fields:\n",
    "            if str(k) in record:\n",
    "                extract[str(k)] = record[k]\n",
    "            else:\n",
    "                # this makes sure we always have the requested fields, even if\n",
    "                # we have a missing value for a given day/month\n",
    "                extract[str(k)] = None\n",
    "        \n",
    "        # add this extraction to the list for the day\n",
    "        result[site]['pollutant_type'][param]['data'][date].append(extract)\n",
    "    \n",
    "    return result\n",
    "'''\n",
    "extract_gaseous = extract_summary_from_response(gaseous_aqi)\n",
    "print(\"Summary of gaseous extraction ...\")\n",
    "#with open('extract_gaseous.json', 'w') as f:\n",
    "#    json.dump(extract_gaseous, f)\n",
    "print(json.dumps(extract_gaseous,indent=4))\n",
    "\n",
    "extract_particulate = extract_summary_from_response(particulate_aqi)\n",
    "print(\"Summary of particulate extraction ...\")\n",
    "#with open('extract_particulate.json', 'w') as f:\n",
    "#    json.dump(extract_particulate, f)\n",
    "print(json.dumps(extract_particulate,indent=4))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4a9142",
   "metadata": {},
   "source": [
    "## Getting data from 1963 to 2023\n",
    "This code was made by me and by the help of ChatGPT. We pull in the requests every year and store them into a JSON file to be used in the `project` file. I gave chatgpt information on what I used to load in the AQI data (ie: `request_daily_summary` and `extract_summary_from_response`), and asked it: \"Make me code to store this data from 1963 - 2023 in seperate JSON files\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd26115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['param'] = AQI_PARAMS_GASEOUS\n",
    "request_data['state'] = CITY_LOCATIONS['mine']['fips'][:2]\n",
    "request_data['county'] = CITY_LOCATIONS['mine']['fips'][2:]\n",
    "\n",
    "# Sample function to pull air quality data and store it into JSON files\n",
    "def fetch_and_store_aqi_data(start_year=1975, end_year=2023):\n",
    "    # Initialize dictionaries to hold the AQI data\n",
    "    gaseous_aqi_data = {}\n",
    "    particulate_aqi_data = {}\n",
    "\n",
    "    # Loop through each year and fire season (May 1st to October 31st)\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        begin_date = f\"{year}0501\"\n",
    "        end_date = f\"{year}1031\"\n",
    "        \n",
    "        request_data['param'] = AQI_PARAMS_GASEOUS\n",
    "        # Assuming request_daily_summary and extract_summary_from_response are your existing functions\n",
    "        gaseous_aqi = request_daily_summary(request_template=request_data, begin_date=begin_date, end_date=end_date)\n",
    "        \n",
    "        request_data['param'] = AQI_PARAMS_PARTICULATES\n",
    "        particulate_aqi = request_daily_summary(request_template=request_data, begin_date=begin_date, end_date=end_date)\n",
    "        \n",
    "        # Extract and organize the AQI data\n",
    "        extract_gaseous = extract_summary_from_response(gaseous_aqi)\n",
    "        extract_particulate = extract_summary_from_response(particulate_aqi)\n",
    "        \n",
    "        # Store the extracted data into dictionaries\n",
    "        gaseous_aqi_data[year] = extract_gaseous\n",
    "        particulate_aqi_data[year] = extract_particulate\n",
    "\n",
    "    # Save the dictionaries to JSON files\n",
    "    with open('gaseous_aqi_data.json', 'w') as f:\n",
    "        json.dump(gaseous_aqi_data, f)\n",
    "        \n",
    "    with open('particulate_aqi_data.json', 'w') as f:\n",
    "        json.dump(particulate_aqi_data, f)\n",
    "\n",
    "fetch_and_store_aqi_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
